# -*- coding: utf-8 -*-
"""Untitled13.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z5yCdcZjMcmBjAgkD8NfMSBZB4sqnSB3
"""

!pip install SentencePiece
!pip install accelerate

import json

# Specify the file path
file_path = "input_for_LLM_news.json"

# Load the JSON file into a dictionary
with open(file_path, 'r') as json_file:
    loaded_dict = json.load(json_file)

# Print the loaded dictionary
print("Loaded Dictionary:", loaded_dict)

from transformers import T5Tokenizer, T5ForConditionalGeneration

tokenizer = T5Tokenizer.from_pretrained("google/flan-t5-xxl")
model = T5ForConditionalGeneration.from_pretrained("google/flan-t5-xxl", device_map="auto")

# input_text = "translate English to German: How old are you?"
# input_ids = tokenizer(input_text, return_tensors="pt").input_ids.to("cuda")

# outputs = model.generate(input_ids)
# print(tokenizer.decode(outputs[0]))
from tqdm import tqdm
output = []
for i in tqdm(loaded_dict['just_qry_prompt'][:100]):
  input_ids = tokenizer(i, return_tensors="pt").input_ids.to("cuda")

  outputs = model.generate(input_ids)
  output.append(tokenizer.decode(outputs[0]))

data = {"LLM_output": output}

import json
with open('LLM_output_just_news_first_100_training.json', 'w') as f:
    json.dump(data, f)

data = {"LLM_output": output}

import json
with open('LLM_output_just_pluse_rev_news_first_100_training.json', 'w') as f:
    json.dump(data, f)

from google.colab import files
files.download('LLM_output_just_pluse_rev_news_first_100_training.json')